<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Graduate Student Project</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Graduate Student Project: Teachable Machines</h1>
    </header>
    
    <nav class="floating-nav">
        <a href="#objectives">Project Objectives</a>
        <a href="#scope">Project Scope</a>
        <a href="#process">Process</a>
        <a href="#lessons">Lessons Learned</a>
        <a href="#video">Video</a>
        <a href="#test-model">Test Model</a>
    </nav>

    <div class="content">
        <section id="objectives" class="section">
            <h2>Project Objectives</h2>
            <p>In this project, we are officially exposed to machine learning. We will use the machine learning algorithm provided by Teachable Machine to train, and combine it with Buolawmini's book to complete this experimental report and thinking.</p>
        </section>

        <section id="scope" class="section">
            <h2>Project Scope</h2>
            <p>Classification:Hand Singal and Music </p>
            <p>Range: 7 hand singals</p>
            <p>Item List:1, 2, 3, 4, 5, 6, 7 </p>
            <p>Image Samples: over 400 of each</p>
            
        </section>

        <section id="process" class="section">
            <h2>Process</h2>
            <p>Before the Test</p>
            <p>Because both of us encountered issue using the CAMERAs, one of our group member ordered a BRAND NEW laptop online to use the CAMERA. We really appreciate this course which help us buying a new laptop with super HD CAMERA.</p>
            <p>TEST 1. Classic Image Classification</p>
            <p>We collect the image samples by recording showing the item in front of the web camera. After the first attempt the precision is not that great.
                 As you can see below, the plier was thought to be a screwdriver</p>
            <img src="training1.png" alt="first attempt">
            <p>Then, we collect more sample for those three kinds of tool to improve the precision and add one more class named "hand" to on behalf of our hands.
                And it is proved that it is better than previous one.
            </p>
            <img src="training2.png" alt="second attempt">
            <p>Following is the video recording the test result</p>
            <video src="Test1/TEST1.mp4" controls></video>
            <p>TEST 2. Classic Sound Classification</p>
            <p>The second test is quite similar to the first one. The only difference is the media form. We replaced the image with sound from different musical instruments including guitar, violin and piano.</p>
            <p>One more thing, we have to record the background noise first to decrease the impact of noise on training.</p>
            <img src="training3.png" alt="second test">
            <video src="Test2/TEST2.mp4" controls></video>
            <p>TEST 3. Play Music With Your Hands</p>
            <p>In this test, we decided to play music just with our own hands, I mean, literally. First of all, we trained the model to identify different hand signals(Which is not standard hand singal) and connect them to 1-7. Then we extracted do re mi fa so ra shi so from a piano video as our "key"s. We make them to several single mp4 file. If the model detect certain hand singal, it will play the scale once. We set 1 second common interval to make it play scale every 1 second</p>
            <p>As you may know, playing music in this way require high precision. We tried 100 sample to train each hand singal but it turned out to be not precise. But when we increase the number of sample to 400 each, the problem could be solved 90%. I think it almost reach the limit of this browser-based model because the webpage almost crashed while preparing the data but managed to make it.</P>
            <p>As I mentioned above, it solve the 90% of the problem. It still make mistake so we have to put our hands really close to the camera and try our best to maintain the same hand signal in training set.
                Here is a example clip of litte star we made. We also deployed this in this page, you can try it yourself.
            </p>
            <video src="Test3/TEST3.mp4" controls></video>

        </section>

        <section id="lessons" class="section">
            <h2>Lessons Learned</h2>
            <p>Joy Buolamwini's Unmasking AI is an in-depth exploration of the ethical implications of artificial intelligence technology, specifically the bias surrounding facial recognition technology and its potential harm to society. Buolamwini uses her own experience and in-depth research to reveal racial, gender, and cultural biases in the design and deployment of artificial intelligence technologies. This book conveys the inequalities that AI technology can cause and calls on technology developers, policymakers, and the public to take action to make AI technology more equitable and just.

            <p>1. Bias in facial recognition technology</p>   
            <p>Buolamwini describes her own research showing that mainstream facial recognition systems have significantly higher error rates in identifying darker-skinned people and women than white men. Her experiments show that the lack of diverse data sets in the design and training of these algorithms leads to systemic bias against non-white groups and women.</p>  
                
            <p>2. Social impact of algorithmic discrimination</p>
            <p>The book discusses the real-world impacts of algorithmic discrimination, particularly in sensitive areas such as law enforcement and public policy. The widespread use of facial recognition technology may exacerbate the problem of over-surveillance and unfair treatment of minority groups. Using examples and statistics, Buolamwini highlights how these technologies can inadvertently reinforce existing social inequalities.</p>
                
            <p>3. Advocate “algorithmic fairness”</p>
            <p>Buolamwini founded the Algorithmic Justice League, which is dedicated to promoting more fair and responsible algorithm development. She called for tighter regulation and testing of algorithms for fairness and accuracy to ensure technology does not unfairly impact certain groups. She specifically called on technology companies and policymakers to listen to the voices of marginalized groups to reduce the adverse impact of technology on these groups.</p>
                
            <p>4. A call for change</p>    
            <p>Buolamwini also offered suggestions for how to change the status quo, including advocating for more inclusive data sets, diversity in technology development processes, and comprehensive assessments of potential bias. By calling on the public, governments, companies, and academia to collaborate, she hopes to build more responsible and ethical AI systems.</p></p>
            <p>Learned</p>
            <p>Our project focuses on analyzing objects through algorithm recognition. In this process, we need to ensure that the algorithm is fair. Joy Buolamwini's "Unmasking AI" provided us with a lot of help and inspiration. I think this book not only tells us the problems of current AI algorithms, but also gives us a reminder. Let all those who will be involved in writing or using mechanical algorithms in the future pay attention to the fairness of algorithms.</p>
        </section>

        <section id="test-model" class="section">
            <h2>Test Model</h2>
            <p>Ready to try our model for yourself? We offer three different categories of tests! Jsut follow our process and have Fun!</p>
            
            <div class="test-model-buttons">
                <a href="Test1/Test1.html" target="_blank" class="custom-button">Test1</a>
                <a href="Test2/Test2.html" target="_blank" class="custom-button">Test2</a>
                <a href="Test3/Test3.html" target="_blank" class="custom-button">Test3</a>
            </div>
        </section>
        
    </div>

    <footer>
        <p>&copy; Rui Xu & Zhihui Lin</p>
    </footer>
</body>
</html>
